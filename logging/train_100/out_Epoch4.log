
Loading checkpoint: hw_asr/default_test_model/model_best_100_3.pth ...
Warning: Optimizer or lr_scheduler given in config file is different from that of checkpoint. Optimizer parameters not being resumed.
Checkpoint loaded. Resume training from epoch 4
['', 'â–in', 'i', 'en', 'g', 'n', 'as', 'ed', '</s>', 'z', '_', 'â–o', 'm', 'nd', 'r', 'in', 'e', 'a', 'â–s', 'is', 'â–h', 'â–th', 'â–d', 'ou', 'f', 'â–f', 'â–he', 'o', 'he', 'â–t', 'â–p', 'l', 'at', 'k', 'â–n', 'an', 'u', 's', '<unk>', 'â–l', 'w', 'es', 'd', 'â–w', '<s>', 'â–c', 'it', 'c', 'â–i', 'â–', 'v', 'j', 'h', 'er', 'q', 'â–b', 'y', 're', 'p', 'b', 'â–to', 'ar', 'â–a', 'ing', 'or', 't', 'x', 'â–of', 'on', 'â–and', 'â–m', 'll', 'â–the']
inside
here
almost
train:   0%|          | 0/951 [00:00<?, ?it/s]








































train:  11%|â–ˆ         | 100/951 [01:26<11:08,  1.27it/s]







































train:  21%|â–ˆâ–ˆ        | 200/951 [02:46<09:48,  1.28it/s]







































train:  32%|â–ˆâ–ˆâ–ˆâ–      | 300/951 [04:06<08:50,  1.23it/s]







































train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 400/951 [05:27<07:19,  1.25it/s]







































train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 500/951 [06:46<06:07,  1.23it/s]







































train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 600/951 [08:05<04:35,  1.27it/s]






































train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 700/951 [09:24<03:19,  1.26it/s]







































train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 800/951 [10:42<02:00,  1.26it/s]






































train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 900/951 [12:02<00:39,  1.30it/s]


















train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 951/951 [12:41<00:00,  1.25it/s]








































test:  15%|â–ˆâ–        | 39/262 [02:12<12:36,  3.39s/it]
Saving model on keyboard interrupt
Saving checkpoint: saved/models/hundred_default_config/1017_151146/checkpoint-epoch4.pth ...
saved/models/hundred_default_config/1017_151146
saved/models/hundred_default_config/1017_151146/config.json
hw_asr/default_test_model/config.json
/home/jupyter/work/resources/ASR_sound/hw_asr/logger/logger_config.json
after BPE train ['â–in', 'i', 'en', 'g', 'n', 'as', 'ed', '</s>', 'z', '_', 'â–o', 'm', 'nd', 'r', 'in', 'e', 'a', 'â–s', 'is', 'â–h', 'â–th', 'â–d', 'ou', 'f', 'â–f', 'â–he', 'o', 'he', 'â–t', 'â–p', 'l', 'at', 'k', 'â–n', 'an', 'u', 's', '<unk>', 'â–l', 'w', 'es', 'd', 'â–w', '<s>', 'â–c', 'it', 'c', 'â–i', 'â–', 'v', 'j', 'h', 'er', 'q', 'â–b', 'y', 're', 'p', 'b', 'â–to', 'ar', 'â–a', 'ing', 'or', 't', 'x', 'â–of', 'on', 'â–and', 'â–m', 'll', 'â–the']
CTC {'â–in': 0, 'i': 1, 'en': 2, 'g': 3, 'n': 4, 'as': 5, 'ed': 6, '</s>': 7, 'z': 8, '_': 9, 'â–o': 10, 'm': 11, 'nd': 12, 'r': 13, 'in': 14, 'e': 15, 'a': 16, 'â–s': 17, 'is': 18, 'â–h': 19, 'â–th': 20, 'â–d': 21, 'ou': 22, 'f': 23, 'â–f': 24, 'â–he': 25, 'o': 26, 'he': 27, 'â–t': 28, 'â–p': 29, 'l': 30, 'at': 31, 'k': 32, 'â–n': 33, 'an': 34, 'u': 35, 's': 36, '<unk>': 37, 'â–l': 38, 'w': 39, 'es': 40, 'd': 41, 'â–w': 42, '<s>': 43, 'â–c': 44, 'it': 45, 'c': 46, 'â–i': 47, 'â–': 48, 'v': 49, 'j': 50, 'h': 51, 'er': 52, 'q': 53, 'â–b': 54, 'y': 55, 're': 56, 'p': 57, 'b': 58, 'â–to': 59, 'ar': 60, 'â–a': 61, 'ing': 62, 'or': 63, 't': 64, 'x': 65, 'â–of': 66, 'on': 67, 'â–and': 68, 'â–m': 69, 'll': 70, 'â–the': 71, '^': 72}
Using arpa instead of binary LM file, decoder instantiation might be slow.
Alphabet determined to be of BPE style.
CTC blank char '' not found, appending to end.
Found <unk> in vocabulary, substituting with â–â‡â–.
Loading the LM will be faster if you build a binary file.
Reading /home/jupyter/work/resources/ASR_sound/BPE_models/lowercase.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
pyctc {0: 'â–in', 1: 'i', 2: 'en', 3: 'g', 4: 'n', 5: 'as', 6: 'ed', 7: '</s>', 8: 'z', 9: '_', 10: 'â–o', 11: 'm', 12: 'nd', 13: 'r', 14: 'in', 15: 'e', 16: 'a', 17: 'â–s', 18: 'is', 19: 'â–h', 20: 'â–th', 21: 'â–d', 22: 'ou', 23: 'f', 24: 'â–f', 25: 'â–he', 26: 'o', 27: 'he', 28: 'â–t', 29: 'â–p', 30: 'l', 31: 'at', 32: 'k', 33: 'â–n', 34: 'an', 35: 'u', 36: 's', 37: 'â–â‡â–', 38: 'â–l', 39: 'w', 40: 'es', 41: 'd', 42: 'â–w', 43: '<s>', 44: 'â–c', 45: 'it', 46: 'c', 47: 'â–i', 48: 'â–', 49: 'v', 50: 'j', 51: 'h', 52: 'er', 53: 'q', 54: 'â–b', 55: 'y', 56: 're', 57: 'p', 58: 'b', 59: 'â–to', 60: 'ar', 61: 'â–a', 62: 'ing', 63: 'or', 64: 't', 65: 'x', 66: 'â–of', 67: 'on', 68: 'â–and', 69: 'â–m', 70: 'll', 71: 'â–the', 72: ''}
TrialModel(
  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (resconv): Sequential(
    (0): ConvBlock(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (layer_norm1): Normalize()
      (layer_norm2): Normalize()
    )
    (1): ConvBlock(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (layer_norm1): Normalize()
      (layer_norm2): Normalize()
    )
    (2): ConvBlock(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (layer_norm1): Normalize()
      (layer_norm2): Normalize()
    )
  )
  (fc_1): Linear(in_features=2048, out_features=512, bias=True)
  (rnn): Sequential(
    (0): RNNBlock(
      (seq): Sequential(
        (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (1): ReLU6()
        (2): GRU(512, 512, batch_first=True, bidirectional=True)
      )
    )
    (1): RNNBlock(
      (seq): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (1): ReLU6()
        (2): GRU(1024, 512, bidirectional=True)
      )
    )
    (2): RNNBlock(
      (seq): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (1): ReLU6()
        (2): GRU(1024, 512, bidirectional=True)
      )
    )
    (3): RNNBlock(
      (seq): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (1): ReLU6()
        (2): GRU(1024, 512, bidirectional=True)
      )
    )
    (4): RNNBlock(
      (seq): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (1): ReLU6()
        (2): GRU(1024, 512, bidirectional=True)
      )
    )
  )
  (fc_2): Linear(in_features=1024, out_features=512, bias=True)
  (out): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): ReLU6()
    (2): Linear(in_features=512, out_features=73, bias=True)
  )
)
Trainable parameters: 23727177